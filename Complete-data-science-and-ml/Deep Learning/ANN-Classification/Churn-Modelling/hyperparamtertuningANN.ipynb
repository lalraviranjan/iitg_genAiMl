{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the optimal number of hidden layers and neurons for an Artificial Neural Network (ANN) \n",
    "This can be challenging and often requires experimentation. However, there are some guidelines and methods that can help you in making an informed decision:\n",
    "\n",
    "- Start Simple: Begin with a simple architecture and gradually increase complexity if needed.\n",
    "- Grid Search/Random Search: Use grid search or random search to try different architectures.\n",
    "- Cross-Validation: Use cross-validation to evaluate the performance of different architectures.\n",
    "- Heuristics and Rules of Thumb: Some heuristics and empirical rules can provide starting points, such as:\n",
    "  -    The number of neurons in the hidden layer should be between the size of the input layer and the size of the output layer.\n",
    "  -  A common practice is to start with 1-2 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline # used for scikit-learn pipelines for preprocessing and model training\n",
    "from scikeras.wrappers import KerasClassifier #used for Keras with scikit-learn for GridSearchCV hyperparameter tuning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Churn_Modelling.csv')\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
    "\n",
    "onehot_encoder_geo = OneHotEncoder(handle_unknown='ignore')\n",
    "geo_encoded = onehot_encoder_geo.fit_transform(data[['Geography']]).toarray()\n",
    "geo_encoded_df = pd.DataFrame(geo_encoded, columns=onehot_encoder_geo.get_feature_names_out(['Geography']))\n",
    "\n",
    "data = pd.concat([data.drop('Geography', axis=1), geo_encoded_df], axis=1)\n",
    "\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save encoders and scaler for later use\n",
    "with open('label_encoder_gender.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder_gender, file)\n",
    "\n",
    "with open('onehot_encoder_geo.pkl', 'wb') as file:\n",
    "    pickle.dump(onehot_encoder_geo, file)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y_train.isna().sum())  # Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create the model\n",
    "def create_model(optimizer='adam', neurons=32, layers=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "\n",
    "    # Add additional layers\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation='relu'))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KerasClassifier\n",
    "# model = KerasClassifier(model=create_model, verbose=1)\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define Keras model wrapper\n",
    "model = KerasClassifier(model=create_model, verbose=1, layers=1, neurons=32, optimizer='adam')\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lalra\\anaconda3\\envs\\deepLearningEnv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\lalra\\anaconda3\\envs\\deepLearningEnv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7466 - loss: 0.5522\n",
      "Epoch 2/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8153 - loss: 0.4344\n",
      "Epoch 3/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8211 - loss: 0.4143\n",
      "Epoch 4/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.4007\n",
      "Epoch 5/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8451 - loss: 0.3799\n",
      "Epoch 6/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8555 - loss: 0.3646\n",
      "Epoch 7/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8574 - loss: 0.3475\n",
      "Epoch 8/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8553 - loss: 0.3484\n",
      "Epoch 9/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8558 - loss: 0.3514\n",
      "Epoch 10/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8623 - loss: 0.3356\n",
      "Best parameters: {'model__batch_size': 16, 'model__epochs': 10, 'model__layers': 1, 'model__neurons': 16, 'model__optimizer': 'adam'}\n",
      "Best accuracy: nan\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m     18\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_result\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m---> 19\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lalra\\anaconda3\\envs\\deepLearningEnv\\Lib\\site-packages\\sklearn\\pipeline.py:1191\u001b[0m, in \u001b[0;36mPipeline.score\u001b[1;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform the data, and apply `score` with the final estimator.\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \n\u001b[0;32m   1157\u001b[0m \u001b[38;5;124;03mCall `transform` of each transformer in the pipeline. The transformed\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;124;03m    Result of calling `score` on the final estimator.\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# TODO(1.8): Remove the context manager and use check_is_fitted(self)\u001b[39;00m\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _raise_or_warn_if_not_fitted(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1192\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m   1193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n",
      "File \u001b[1;32mc:\\Users\\lalra\\anaconda3\\envs\\deepLearningEnv\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lalra\\anaconda3\\envs\\deepLearningEnv\\Lib\\site-packages\\sklearn\\pipeline.py:60\u001b[0m, in \u001b[0;36m_raise_or_warn_if_not_fitted\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# we only get here if the above didn't raise\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     check_is_fitted(estimator)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError:\n\u001b[0;32m     62\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis Pipeline instance is not fitted yet. Call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappropriate arguments before using other methods such as transform, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m     68\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lalra\\anaconda3\\envs\\deepLearningEnv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1756\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mrequires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\lalra\\anaconda3\\envs\\deepLearningEnv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1665\u001b[0m, in \u001b[0;36m_is_fitted\u001b[1;34m(estimator, attributes, all_or_any)\u001b[0m\n\u001b[0;32m   1662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m all_or_any([\u001b[38;5;28mhasattr\u001b[39m(estimator, attr) \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m attributes])\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_is_fitted__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m estimator\u001b[38;5;241m.\u001b[39m__sklearn_is_fitted__()\n\u001b[0;32m   1667\u001b[0m fitted_attrs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1668\u001b[0m     v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1669\u001b[0m ]\n\u001b[0;32m   1670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fitted_attrs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\lalra\\anaconda3\\envs\\deepLearningEnv\\Lib\\site-packages\\sklearn\\pipeline.py:1321\u001b[0m, in \u001b[0;36mPipeline.__sklearn_is_fitted__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;66;03m# check if the last step of the pipeline is fitted\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;66;03m# we only check the last step since if the last step is fit, it\u001b[39;00m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;66;03m# means the previous steps should also be fit. This is faster than\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;66;03m# checking if every step of the pipeline is fit.\u001b[39;00m\n\u001b[1;32m-> 1321\u001b[0m     check_is_fitted(last_step)\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError:\n",
      "File \u001b[1;32mc:\\Users\\lalra\\anaconda3\\envs\\deepLearningEnv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1751\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m-> 1751\u001b[0m tags \u001b[38;5;241m=\u001b[39m get_tags(estimator)\n\u001b[0;32m   1753\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mrequires_fit \u001b[38;5;129;01mand\u001b[39;00m attributes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lalra\\anaconda3\\envs\\deepLearningEnv\\Lib\\site-packages\\sklearn\\utils\\_tags.py:430\u001b[0m, in \u001b[0;36mget_tags\u001b[1;34m(estimator)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39mmro()):\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sklearn_tags__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[1;32m--> 430\u001b[0m         sklearn_tags_provider[klass] \u001b[38;5;241m=\u001b[39m klass\u001b[38;5;241m.\u001b[39m__sklearn_tags__(estimator)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    431\u001b[0m         class_order\u001b[38;5;241m.\u001b[39mappend(klass)\n\u001b[0;32m    432\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_more_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "File \u001b[1;32mc:\\Users\\lalra\\anaconda3\\envs\\deepLearningEnv\\Lib\\site-packages\\sklearn\\base.py:540\u001b[0m, in \u001b[0;36mClassifierMixin.__sklearn_tags__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m__sklearn_tags__()\n\u001b[0;32m    541\u001b[0m     tags\u001b[38;5;241m.\u001b[39mestimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    542\u001b[0m     tags\u001b[38;5;241m.\u001b[39mclassifier_tags \u001b[38;5;241m=\u001b[39m ClassifierTags()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'model__optimizer': ['adam', 'rmsprop'],  # Optimizers to try\n",
    "    'model__neurons': [16, 32],               # Number of neurons to try\n",
    "    'model__layers': [1, 3],                  # Number of layers to try\n",
    "    'model__batch_size': [16, 32],            # Batch sizes to try\n",
    "    'model__epochs': [10, 20]                 # Number of epochs to try\n",
    "}\n",
    "# Note: The batch size and epochs are not included in the pipeline as they are passed directly to the KerasClassifier\n",
    "\n",
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=pipeline, param_grid=param_grid, n_jobs=-1, cv=2)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "# Print the best parameters and accuracy\n",
    "print(f\"Best parameters: {grid_result.best_params_}\")\n",
    "print(f\"Best accuracy: {grid_result.best_score_}\")\n",
    "# Evaluate the model on the test set\n",
    "# best_model = grid_result.best_estimator_\n",
    "# test_accuracy = best_model.score(X_test, y_test)\n",
    "# print(f\"Test accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearningEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
