{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1565f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arxiv Researcg\n",
    "# Import Tools Library\n",
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5d3516e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#usinh inbuilt tool of wiki\n",
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "715331e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=500)\n",
    "arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61542b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import RAG tools\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58f339e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000023D28DB2CF0>, search_kwargs={})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://www.ibm.com/think/topics/agentic-ai-vs-generative-ai\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)\n",
    "vectorDb = FAISS.from_documents(documents=documents, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorDb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a06310d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ibm_genai_search'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the retriever into a tool\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(retriever, \"ibm_genai_search\", \"Search any information about GenAi or Agentic Ai\")\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04084f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\lalra\\\\anaconda3\\\\envs\\\\huggingface\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=500)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=500)),\n",
       " Tool(name='ibm_genai_search', description='Search any information about GenAi or Agentic Ai', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000023CDAC16F20>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000023D28DB2CF0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000023CDAC172E0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000023D28DB2CF0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [wiki, arxiv, retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d831a72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000023D28AA08F0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000023D28F51400>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run all the tools using Agents and LLM models\n",
    "#Combine the tools with LLM-> AgentExecutor\n",
    "from langchain_groq import ChatGroq\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key, model=\"Gemma2-9b-It\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "36c9bbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now create out Prompt Template\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ce09eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000023CDA4D5940>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000023CDA4D5940>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000023D28AA08F0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000023D28F51400>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'ibm_genai_search', 'description': 'Search any information about GenAi or Agentic Ai', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm,tools,prompt)\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73c0f003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000023CDA4D5940>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000023CDA4D5940>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000023D28AA08F0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000023D28F51400>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'ibm_genai_search', 'description': 'Search any information about GenAi or Agentic Ai', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\lalra\\\\anaconda3\\\\envs\\\\huggingface\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=500)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=500)), Tool(name='ibm_genai_search', description='Search any information about GenAi or Agentic Ai', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000023CDAC16F20>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000023D28DB2CF0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000023CDAC172E0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000023D28DB2CF0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Agent Executor\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bcd9469f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `ibm_genai_search` with `{'query': 'Agentic AI use cases in Healthcare'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mAgentic AI use cases\n",
      "\n",
      "\n",
      "Customer service\n",
      "\n",
      "\n",
      "The traditional models for customer chatbots had limitations due to the pre-programmed nature of the technology and would require human intervention at times. Whereas with autonomous agents, the model can quickly understand what a customer's intent and emotion is and take steps to resolve the issue.\n",
      "\n",
      "These autonomous systems can therefore predictively assess a situation and help ensure a smoother customer interaction with a business. The customer experience is exceedingly important in the world today as businesses seek out higher retention and enhanced loyalty. Specifically, agentic AI can automate tedious tasks by gathering, cleaning, and formatting an organization’s data. These systems can take the weight off of human employees and free them up to do more high-impact projects and tasks.\n",
      "\n",
      "\n",
      "Healthcare\n",
      "\n",
      "Healthcare\n",
      "\n",
      "\n",
      "AI technology has been used in the healthcare field already, including in diagnostics, patient care, and streamlining administrative tasks. Cybersecurity is one of the most vital features of any AI tool that is used in the healthcare space due to patient data and privacy concerns. This concern carries over into emerging agentic AI tools as well.\n",
      "\n",
      "A potential use case example comes from Propeller Health, which is integrating agentic AI into its smart inhaler technology. The smart device is collecting real-time data from the patient on medication usage and outside factors like air quality. The device alerts healthcare providers when necessary and tracks patient patterns.\n",
      "\n",
      "\n",
      "Automated workflow management\n",
      "\n",
      "Agentic AI and AI agents\n",
      "\n",
      "Agentic AI trends\u001b[0m\u001b[32;1m\u001b[1;3mAgentic AI is poised to revolutionize healthcare by automating tasks, improving patient care, and streamlining workflows. \n",
      "\n",
      "One example mentioned is Propeller Health's smart inhaler, which uses agentic AI to collect real-time data from patients and alert healthcare providers when necessary.  This can help ensure patients are taking their medication correctly and identify potential issues early on.\n",
      "\n",
      "\n",
      "Agentic AI can also be used to automate administrative tasks, freeing up healthcare professionals to focus on patient care.  For example, agentic AI could be used to schedule appointments, manage patient records, and process insurance claims.\n",
      "\n",
      "However, the text also highlights the importance of cybersecurity in healthcare AI, as patient data is highly sensitive.  \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Tell me about Agentic AI use cases in Healthcare', 'output': \"Agentic AI is poised to revolutionize healthcare by automating tasks, improving patient care, and streamlining workflows. \\n\\nOne example mentioned is Propeller Health's smart inhaler, which uses agentic AI to collect real-time data from patients and alert healthcare providers when necessary.  This can help ensure patients are taking their medication correctly and identify potential issues early on.\\n\\n\\nAgentic AI can also be used to automate administrative tasks, freeing up healthcare professionals to focus on patient care.  For example, agentic AI could be used to schedule appointments, manage patient records, and process insurance claims.\\n\\nHowever, the text also highlights the importance of cybersecurity in healthcare AI, as patient data is highly sensitive.  \\n\"}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\": \"Tell me about Agentic AI use cases in Healthcare\"})\n",
    "print(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2709998e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic AI is poised to revolutionize healthcare by automating tasks, improving patient care, and streamlining workflows. \n",
      "\n",
      "One example mentioned is Propeller Health's smart inhaler, which uses agentic AI to collect real-time data from patients and alert healthcare providers when necessary.  This can help ensure patients are taking their medication correctly and identify potential issues early on.\n",
      "\n",
      "\n",
      "Agentic AI can also be used to automate administrative tasks, freeing up healthcare professionals to focus on patient care.  For example, agentic AI could be used to schedule appointments, manage patient records, and process insurance claims.\n",
      "\n",
      "However, the text also highlights the importance of cybersecurity in healthcare AI, as patient data is highly sensitive.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['output']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4b28abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'attention is all you need'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2024-07-22\n",
      "Title: Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models\n",
      "Authors: Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini\n",
      "Summary: The inference demand for LLMs has skyrocketed in recent months, and serving\n",
      "models with low latencies remains challenging due to the quadratic input length\n",
      "complexity of the attention layers. In this work, we investigate the effect of\n",
      "dropping MLP and attention layers at inference time o\u001b[0m\u001b[32;1m\u001b[1;3m\"Attention Is All You Need\" is a groundbreaking paper in the field of natural language processing (NLP).  \n",
      "\n",
      "It introduced the Transformer architecture, a novel neural network design that relies entirely on attention mechanisms to process sequential data like text. This architecture significantly outperformed previous models in tasks like machine translation, demonstrating the power of attention in capturing long-range dependencies and relationships within text.  \n",
      "\n",
      "The paper's core idea is that attention allows a model to focus on the most relevant parts of an input sequence when generating an output. This eliminates the need for recurrent networks, which process information sequentially and struggle with long sequences, and enables parallel processing, leading to faster training and inference. \n",
      "\n",
      "\n",
      "Let me know if you want to know more about Transformers or the \"Attention Is All You Need\" paper!\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What is attention is all you need', 'output': '\"Attention Is All You Need\" is a groundbreaking paper in the field of natural language processing (NLP).  \\n\\nIt introduced the Transformer architecture, a novel neural network design that relies entirely on attention mechanisms to process sequential data like text. This architecture significantly outperformed previous models in tasks like machine translation, demonstrating the power of attention in capturing long-range dependencies and relationships within text.  \\n\\nThe paper\\'s core idea is that attention allows a model to focus on the most relevant parts of an input sequence when generating an output. This eliminates the need for recurrent networks, which process information sequentially and struggle with long sequences, and enables parallel processing, leading to faster training and inference. \\n\\n\\nLet me know if you want to know more about Transformers or the \"Attention Is All You Need\" paper!\\n'}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\": \"What is attention is all you need\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "35e55891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Attention Is All You Need\" is a groundbreaking paper in the field of natural language processing (NLP).  \n",
      "\n",
      "It introduced the Transformer architecture, a novel neural network design that relies entirely on attention mechanisms to process sequential data like text. This architecture significantly outperformed previous models in tasks like machine translation, demonstrating the power of attention in capturing long-range dependencies and relationships within text.  \n",
      "\n",
      "The paper's core idea is that attention allows a model to focus on the most relevant parts of an input sequence when generating an output. This eliminates the need for recurrent networks, which process information sequentially and struggle with long sequences, and enables parallel processing, leading to faster training and inference. \n",
      "\n",
      "\n",
      "Let me know if you want to know more about Transformers or the \"Attention Is All You Need\" paper!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fe1f223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Hanuman'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Hanuman\n",
      "Summary: Hanuman (; Sanskrit: हनुमान्, IAST: Hanumān), also known as Maruti, Bajrangabali, and Anjaneya, is a deity in Hinduism, revered as a divine vanara, and a devoted companion of the deity Rama. Central to the Ramayana, Hanuman is celebrated for his unwavering devotion to Rama and is considered a chiranjivi. He is traditionally believed to be the spiritual offspring of the wind deity Vayu, who is said to have played a significant role in his birth. In Shaiva tradition, he is r\u001b[0m\u001b[32;1m\u001b[1;3mHanuman (; Sanskrit: हनुमान्, IAST: Hanumān), also known as Maruti, Bajrangabali, and Anjaneya, is a deity in Hinduism, revered as a divine vanara, and a devoted companion of the deity Rama. \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Who is lord Hanuman', 'output': 'Hanuman (; Sanskrit: हनुमान्, IAST: Hanumān), also known as Maruti, Bajrangabali, and Anjaneya, is a deity in Hinduism, revered as a divine vanara, and a devoted companion of the deity Rama. \\n'}\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\": \"Who is lord Hanuman\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "270f14a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hanuman (; Sanskrit: हनुमान्, IAST: Hanumān), also known as Maruti, Bajrangabali, and Anjaneya, is a deity in Hinduism, revered as a divine vanara, and a devoted companion of the deity Rama. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
